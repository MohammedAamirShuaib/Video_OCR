{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "import os\n",
    "import pytesseract\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = os.listdir(\"videos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for video in videos:\n",
    "    vf = \"videos/\"+video\n",
    "    os.mkdir(\"frames/\"+video[:-4])\n",
    "    f_path = \"frames/\"+video[:-4]+\"/\"\n",
    "    # Frame Creation \n",
    "    vidcap = cv2.VideoCapture(vf)\n",
    "    fps = int(vidcap.get(cv2.CAP_PROP_FPS))\n",
    "    frame_count = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    duration = frame_count/fps\n",
    "    #print('video length ',duration,' seconds')\n",
    "    #print('frames per second ',fps)\n",
    "    saved_im=[]\n",
    "    data_im=[]\n",
    "    success,image = vidcap.read()\n",
    "    filename =\"frame%d.jpg\" % 0;\n",
    "    cv2.imwrite(f_path+filename, image)     # save frame as JPEG file  ## not saving files but writing to csv    \n",
    "    success,image = vidcap.read()\n",
    "    saved_im.append(filename)\n",
    "    data_im.append(image)\n",
    "    count = 1\n",
    "    frame_list=['frame0.jpg']\n",
    "    while success:\n",
    "        filename =\"frame%d.jpg\" % count;\n",
    "        count += 1\n",
    "        if count % fps == 0:\n",
    "            cv2.imwrite(f_path+filename, image)\n",
    "            saved_im.append(filename)\n",
    "            data_im.append(image)\n",
    "            frame_list.append(filename)\n",
    "        success,image = vidcap.read()\n",
    "    df = pd.DataFrame(frame_list)\n",
    "    df.to_csv('frames/'+video[:-4]+'/frame_list.csv',index=False)\n",
    "    print(\"Completed making frames for {}\".format(video))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing Duplicate Frames\n",
    "for video in videos:\n",
    "    f_path = \"frames/\"+video[:-4]+\"/\"\n",
    "    df = pd.read_csv(f_path+'frame_list.csv')\n",
    "    frame_list=df[\"0\"].tolist()\n",
    "    comparing_frame= frame_list[0]\n",
    "    final_frames= ['frame0.jpg']\n",
    "\n",
    "    for i in range(1,len(frame_list)):\n",
    "        comparing_path = f_path+comparing_frame\n",
    "        frame_path = f_path+frame_list[i]\n",
    "        frame= frame_list[i]\n",
    "        f1 = Image.open(comparing_path)\n",
    "        f2 = Image.open(frame_path)\n",
    "        # i am also reducing the shape by half just to save some processing power\n",
    "        f1_reshape = f1.resize((round(f1.size[0]*0.5), round(f1.size[1]*0.5)))\n",
    "        f2_reshape = f2.resize((round(f1.size[0]*0.5), round(f1.size[1]*0.5)))\n",
    "        # convert the images to (R,G,B) arrays\n",
    "        f_array1 = np.array(f1_reshape).flatten()/255\n",
    "        f_array2 = np.array(f2_reshape).flatten()/255\n",
    "        similarity = -1 * (spatial.distance.cosine(f_array1, f_array2) - 1)\n",
    "        if similarity<0.98:\n",
    "            comparing_frame = frame_list[i]\n",
    "            final_frames.append(frame)\n",
    "\n",
    "    final_frames[:5]\n",
    "    df = pd.DataFrame(final_frames)\n",
    "    df.to_csv(f_path+'/final_frames.csv',index=False)\n",
    "    print(\"Completed scanning duplicate frames for {}\".format(video))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OCR \n",
    "for video in videos:\n",
    "    f_path = \"frames/\"+video[:-4]+\"/\"\n",
    "    df = pd.read_csv(f_path+'frame_list.csv')\n",
    "    final_frames=df[\"0\"].tolist()\n",
    "    ocr_list = []\n",
    "    for f in final_frames:\n",
    "        path = f_path+f\n",
    "        img = cv2.imread(path)\n",
    "        gray = get_grayscale(img)\n",
    "        \n",
    "        # configurations ENG+ARABIC\n",
    "        config = ('-l eng+ara --oem 0 --psm 3')\n",
    "        # pytessercat\n",
    "        text = pytesseract.image_to_string(gray, config=config)\n",
    "        # print text\n",
    "        text = text.split('\\n')\n",
    "        ocr_list.append(text)\n",
    "\n",
    "    df = pd.DataFrame([final_frames,ocr_list]).T\n",
    "    df.to_csv(\"frames/\"+video[:-4]+\"/ocr_list.csv\",index=False)\n",
    "    print(\"Completed OCR for {}\".format(video))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get grayscale image\n",
    "def get_grayscale(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# noise removal\n",
    "def remove_noise(image):\n",
    "    return cv2.medianBlur(image,5)\n",
    " \n",
    "#thresholding\n",
    "def thresholding(image):\n",
    "    return cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "#dilation\n",
    "def dilate(image):\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    return cv2.dilate(image, kernel, iterations = 1)\n",
    "    \n",
    "#erosion\n",
    "def erode(image):\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    return cv2.erode(image, kernel, iterations = 1)\n",
    "\n",
    "#opening - erosion followed by dilation\n",
    "def opening(image):\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    return cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "#canny edge detection\n",
    "def canny(image):\n",
    "    return cv2.Canny(image, 100, 200)\n",
    "\n",
    "#skew correction\n",
    "def deskew(image):\n",
    "    coords = np.column_stack(np.where(image > 0))\n",
    "    angle = cv2.minAreaRect(coords)[-1]\n",
    "    if angle < -45:\n",
    "        angle = -(90 + angle)\n",
    "    else:\n",
    "        angle = -angle\n",
    "    (h, w) = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "    return rotated\n",
    "\n",
    "\n",
    "def match_template(image, template):\n",
    "    return cv2.matchTemplate(image, template, cv2.TM_CCOEFF_NORMED) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7aa4d19a638a80da7a7ade909e3c19fe71645a572a3b82d5be58130c5ff9d30d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 ('ocr': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
